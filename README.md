# AI Engineer Learning Journal

Welcome to my **AI Engineer learning journal**!  
This repo documents my path from foundational machine learning to advanced large language models (LLMs), tool development, and orchestration in real-world developer workflows.  

Each week contains:  
- **Lessons.md** â†’ notes, key takeaways, Q&A  
- **Mini-project.ipynb** â†’ small coding exercises or demos  
- **README.md** â†’ weekly summary and reflections  

I will also try to create LinkedIn posts to share my progress and insights. Follow me [here](https://www.linkedin.com/in/marcdacanay/) and let's learn together!

---

## ðŸ—“ High-Level Weekly Plan

### **Week 1 â€“ Fast Foundations**
- Core math for ML: linear algebra, probability, statistics  
- Intro to ML concepts: supervised & unsupervised learning  
- Neural network intuition  
- Mini-projects: image as matrix, coin toss simulation, simple classifiers  
- **Goal:** Establish base for understanding LLMs and ML pipelines  

### **Week 2 â€“ ML to Transformers**
- Quick recap of ML models: logistic regression, decision trees  
- Deep learning basics: CNNs, RNNs, simple feedforward networks  
- Transformers: attention mechanism, positional encoding  
- Mini-projects: small neural network, tiny attention demo  
- **Goal:** Understand the architecture that powers LLMs  

### **Week 3 â€“ LLM Fundamentals**
- Intro to large language models (GPT, BERT, LLaMA)  
- Tokenization, embeddings, context windows  
- Pretraining vs fine-tuning concepts  
- Mini-projects: generate text using small pre-trained models  
- **Goal:** Get hands-on with real LLMs and understand their mechanics  

### **Week 4 â€“ Fine-Tuning & Custom LLMs**
- Parameter-efficient fine-tuning (LoRA, PEFT)  
- Dataset preparation for LLMs  
- Mini-projects: fine-tune small LLM on custom dataset  
- **Goal:** Build practical understanding of LLM customization  

### **Week 5 â€“ Retrieval-Augmented Generation (RAG)**
- Concept of RAG pipelines: embeddings + vector DB + LLM  
- Mini-projects: PDF Q&A bot, small knowledge base query  
- **Goal:** Enable LLMs to work with external knowledge effectively  

### **Week 6 â€“ Tooling & Orchestration**
- LangChain, LlamaIndex, MCP server basics  
- Automating tasks with LLMs  
- Mini-projects: small workflow or agent connecting multiple LLM calls  
- **Goal:** Learn to integrate LLMs into developer workflows  

### **Week 7 â€“ Local LLMs**
- Running LLMs locally (Ollama, llama.cpp, vLLM)  
- Quantized models, embeddings, local RAG  
- Mini-projects: offline chatbot or personal assistant  
- **Goal:** Build practical skills running models without cloud dependency  

### **Week 8 â€“ Advanced Tooling & LLM Projects**
- Multi-agent frameworks (AutoGen, CrewAI)  
- LLMOps: monitoring, evaluation, deployment  
- Mini-projects: local assistant with multiple agents, GitHub CI/CD bot  
- **Goal:** Complete hands-on projects for portfolio  

### **Weeks 9+ â€“ Portfolio Projects**
- Consolidate projects into reusable tools or demos  
- Document each project with lessons learned  
- Prepare public portfolio / showcase for recruiters or collaborators  

---

## ðŸ“Œ Notes
- Each weekâ€™s folder contains lessons, mini-projects, and weekly summary.  
- This repo is both a **learning journal** and a **portfolio of applied AI projects**.  

---